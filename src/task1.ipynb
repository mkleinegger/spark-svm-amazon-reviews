{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e4a49d",
   "metadata": {},
   "source": [
    "Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37820f79-5424-48c2-8677-77dde8ee0390",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://captain01.os.hpc.tuwien.ac.at:9999/proxy/application_1715326141961_0590\n",
       "SparkContext available as 'sc' (version = 3.2.3, master = yarn, app id = application_1715326141961_0590)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "sc: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2365b18e\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val sc = SparkSession.builder\n",
    ".appName(\"ChiSquaredRDD\")\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4a6d0",
   "metadata": {},
   "source": [
    "Load amazon reviews and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1912d27-b756-4c23-a833-8027b9f160f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[26] at rdd at <console>:28\n",
       "import scala.io.Source.fromFile\n",
       "stopwords: Array[String] = Array(a, aa, able, about, above, absorbs, accord, according, accordingly, across, actually, after, afterwards, again, against, ain, album, album, all, allow, allows, almost, alone, along, already, also, although, always, am, among, amongst, an, and, another, any, anybody, anyhow, anyone, anything, anyway, anyways, anywhere, apart, app, appear, appreciate, appropriate, are, aren, around, as, aside, ask, asking, associated, at, available, away, awfully, b, baby, bb, be, became, because, become, becomes, becoming, been, before, beforehand, behind, being, believe, below, beside, besides, best, better, between, beyond, bibs, bike...\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val reviews = sc\n",
    ".read.json(\"hdfs:///user/dic24_shared/amazon-reviews/full/reviews_devset.json\")\n",
    ".select(\"category\",\"reviewText\").rdd\n",
    "\n",
    "import scala.io.Source.fromFile\n",
    "val stopwords = fromFile(\"../data/stopwords.txt\").getLines.toArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc425da0",
   "metadata": {},
   "source": [
    "Calculate Chi Sqaure values and output top k (=75) words by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89fed35-7beb-40e8-8dd3-ba59cd10aab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "// avg. 44 seconds\n",
    "\n",
    "val n_docs_by_cat = reviews\n",
    ".map(row => (row.getString(0), 1))\n",
    ".countByKey()\n",
    ".toMap\n",
    "\n",
    "val N = reviews.count()\n",
    "\n",
    "\n",
    "def preprocess(text: String): Array[String] = {\n",
    "  text.toLowerCase.split(\"[^a-zA-Z<>^|]+\")\n",
    "      .filter(word => !stopwords.contains(word) && word.length > 1)\n",
    "      .distinct\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "val filteredRDD = reviews.map(row => (row.getString(0), preprocess(row.getString(1))))\n",
    "\n",
    "val a = filteredRDD\n",
    ".flatMapValues(terms => terms)\n",
    ".map({ case (category, term) => ((category, term), 1) })\n",
    ".reduceByKey(_ + _)\n",
    ".map({ case ((category, term), count) => (term, (category, count)) })\n",
    "\n",
    "\n",
    "def reducer_token_sum(token: String, values: Iterable[(String, Int)]): Traversable[(String, (String, Double))] = {\n",
    "  val counts = values.toMap\n",
    "  val n_t = counts.values.sum\n",
    "  counts.map { case (category, count) =>  //(category, (token, count, n_t))\n",
    "    val A = count\n",
    "    val B = n_t - A\n",
    "    val C = n_docs_by_cat(category) - A \n",
    "    val D = N - A - B - C\n",
    "    val chisquared = (N * math.pow((A * D) - (B * C), 2)) / ((A + B) * (A + C) * (B + D) * (C + D))\n",
    "    (category, (token, chisquared ))\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "val b = a.groupByKey.flatMap { case (key, value) => reducer_token_sum(key, value) } \n",
    "b.collect()\n",
    "\n",
    "\n",
    "val topK = b.groupByKey()\n",
    ".mapValues(_.toList.sortBy(-_._2).take(75))\n",
    ".sortByKey()\n",
    "\n",
    "\n",
    "val output = topK.map(row => {\n",
    "    val key = row._1\n",
    "    val values = row._2.map { case (str, num) => s\"$str:$num\" }.mkString(\" \")\n",
    "    s\"<$key> $values\"\n",
    "})\n",
    "\n",
    "\n",
    "import java.io.PrintWriter\n",
    "def writeRDDToFile(rdd: org.apache.spark.rdd.RDD[String], filePath: String): Unit = {\n",
    "    val writer = new PrintWriter(filePath)\n",
    "    rdd.collect().foreach(line => writer.println(line))\n",
    "    writer.close()\n",
    "}\n",
    "\n",
    "writeRDDToFile(output, \"../data/output_rdd.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3715d-7066-4a79-9fee-3b3bd8917c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e025568-b01c-4681-b26b-42ab6f55c48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
