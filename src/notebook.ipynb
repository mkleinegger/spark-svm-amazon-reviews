{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Text Processing and Classification using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "spark: SparkSession = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 75\n",
    "FILE_PATH = 'hdfs:///user/dic24_shared/amazon-reviews/full/reviews_devset.json' # devset\n",
    "# FILE_PATH = 'hdfs:///user/dic24_shared/amazon-reviews/full/reviewscombined.json' # full dataset\n",
    "\n",
    "df = spark.read.json(FILE_PATH)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/stopwords.txt') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "tokens = F.lower(F.col('reviewText'))\n",
    "tokens = F.split(tokens, r'[^a-zA-Z<>^|]+')\n",
    "tokens = F.filter(tokens, lambda token: F.length(token) > 1 and (token not in stopwords))\n",
    "tokens = F.array_distinct(tokens)\n",
    "tokens = F.explode(tokens)\n",
    "df = df.withColumn('token', )\n",
    "df = df[['category', 'token']]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.withColumn('n_c_t', F.count(F.expr('*')).over(Window.partitionBy('category', 'token')))\n",
    "counts = counts.withColumn('n_t', F.count(F.expr('*')).over(Window.partitionBy('token')))\n",
    "counts = counts.withColumn('n_c', F.count(F.expr('*')).over(Window.partitionBy('category')))\n",
    "counts = counts.withColumn('n', F.lit(counts.count()))\n",
    "# counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq = counts.withColumn('a', F.col('n_c_t'))\n",
    "chisq = chisq.withColumn('b', F.col('n_c') - F.col('a'))\n",
    "chisq = chisq.withColumn('c', F.col('n_t') - F.col('a'))\n",
    "chisq = chisq.withColumn('d', F.col('n') - F.col('a') - F.col('b') - F.col('c'))\n",
    "chisq = chisq.withColumn('chi_squared', F.col('n') * ((F.col('a') * F.col('d') - F.col('b') * F.col('c')) ** 2) / ((F.col('a') + F.col('b')) * (F.col('c') + F.col('d')) * (F.col('a') + F.col('c')) * (F.col('b') + F.col('d'))))\n",
    "chisq = chisq[['category', 'token', 'chi_squared']]\n",
    "# chisq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = chisq.withColumn('rank', F.rank().over(Window.partitionBy('category').orderBy(F.desc('chi_squared'))))\n",
    "topk = topk.filter(F.col('rank') <= K)\n",
    "topk = topk.withColumn('topk', F.array('token', 'chi_squared'))\n",
    "topk = topk.groupBy('category').agg(F.collect_list('topk').alias('topk'))\n",
    "topk = topk.sort('category')\n",
    "# topk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt', 'w') as f:\n",
    "    tokens = set()\n",
    "\n",
    "    for row in topk.collect():\n",
    "        tokens.update(map(lambda x: x[0], row['topk']))\n",
    "        value_strings = [f'{value[1]}:{value[0]}' for value in row['topk']]\n",
    "        print(' '.join([f'<{row[\"category\"]}>'] + value_strings), file=f)\n",
    "\n",
    "    print(' '.join(sorted(tokens)), file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DIC24)",
   "language": "python",
   "name": "python3_dic24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
