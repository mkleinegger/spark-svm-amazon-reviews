{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c49e0cd7-dab4-45e4-a9db-6764e78861d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.DataFrame\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.ml.feature.{StringIndexer, HashingTF, IDF, RegexTokenizer, StopWordsRemover, ChiSqSelector}\n",
       "import org.apache.spark.ml.classification.{LinearSVC, OneVsRest}\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
       "import org.apache.spark.ml.feature.Normalizer\n",
       "import org.apache.spark.ml.Pipeline\n",
       "import org.apache.spark.ml.util.DefaultParamsWritable\n",
       "import scala.io.Source.fromFile\n"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.ml.feature.{StringIndexer,HashingTF,IDF,RegexTokenizer,StopWordsRemover,ChiSqSelector}\n",
    "import org.apache.spark.ml.classification.{LinearSVC, OneVsRest}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.Normalizer\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.util.DefaultParamsWritable\n",
    "import scala.io.Source.fromFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427ab466-b9bd-4e74-a6f7-fe2d17155450",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://captain01.os.hpc.tuwien.ac.at:9999/proxy/application_1715326141961_0598\n",
       "SparkContext available as 'sc' (version = 3.2.3, master = yarn, app id = application_1715326141961_0598)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "sc: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@4c35d2ad\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val sc = SparkSession.builder\n",
    ".appName(\"SVM Text Classification\")\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e88b7bc-c386-43d5-82fd-92c564358932",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_to_stopwords: String = ../data/stopwords.txt\n",
       "k: Int = 2000\n",
       "split_pattern: String = [^a-zA-Z<>^|]+\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path_to_stopwords = \"../data/stopwords.txt\"\n",
    "\n",
    "val k = 2000\n",
    "val split_pattern = \"[^a-zA-Z<>^|]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "697fd568-10bf-4ce6-8917-69f390b888bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reviewsDF: org.apache.spark.sql.DataFrame = [category: string, reviewText: string]\n",
       "stopwords: Array[String] = Array(a, aa, able, about, above, absorbs, accord, according, accordingly, across, actually, after, afterwards, again, against, ain, album, album, all, allow, allows, almost, alone, along, already, also, although, always, am, among, amongst, an, and, another, any, anybody, anyhow, anyone, anything, anyway, anyways, anywhere, apart, app, appear, appreciate, appropriate, are, aren, around, as, aside, ask, asking, associated, at, available, away, awfully, b, baby, bb, be, became, because, become, becomes, becoming, been, before, beforehand, behind, being, believe, below, beside, besides, best, better, between, beyond, bibs, bike, book, books, both, brief, bulbs, but, by, c, came, ca...\n"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val reviewsDF = sc\n",
    ".read.json(\"hdfs:///user/dic24_shared/amazon-reviews/full/reviews_devset.json\")\n",
    ".select(\"category\",\"reviewText\")\n",
    "\n",
    "val stopwords = fromFile(path_to_stopwords).getLines.toArray\n",
    "\n",
    "reviewsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1e5045a2-6da9-46e3-a9a5-302a3b28f132",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.StopWordsRemover\n",
       "defined class CustomStopWordsRemover\n",
       "defined class CustomTokenizer\n",
       "tokenizer: org.apache.spark.ml.feature.RegexTokenizer = RegexTokenizer: uid=regexTok_24b3d5d79e92, minTokenLength=1, gaps=true, pattern=[^a-zA-Z<>^|]+, toLowercase=true\n",
       "stopWordsFile: String = ../data/stopwords.txt\n",
       "remover: org.apache.spark.ml.feature.StopWordsRemover = StopWordsRemover: uid=stopWords_db93a2ff66b4, numStopWords=596, locale=en_US, caseSensitive=false\n",
       "hashingTF: org.apache.spark.ml.feature.HashingTF = HashingTF: uid=hashingTF_fd33752c86aa, binary=false, numFeatures=262144\n",
       "idf: org.apache.spark.ml.feature.IDF = idf_0844db36dcd2\n",
       "indexer: org.apache.spark.ml.feature.StringIndexer = strIdx_9f25dcec4ab9\n",
       "selector: org.apache.spark.ml.feature.ChiSqSelector = chi...\n"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.StopWordsRemover\n",
    "class CustomStopWordsRemover(stopWordsFile: String) extends StopWordsRemover(stopWordsFile) {\n",
    "    // load and set custom stop words\n",
    "    val customStopWords: Array[String] = scala.io.Source.fromFile(stopWordsFile).getLines.toArray\n",
    "    setStopWords(customStopWords)    \n",
    "}\n",
    "\n",
    "class CustomTokenizer extends Tokenizer with DefaultParamsWritable {\n",
    "  // use splitting pattern from exercise 1\n",
    "  override protected def createTransformFunc: String => Seq[String] = { input =>\n",
    "    input.toLowerCase.split(split_pattern).toSeq.filter(_.length > 1)\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "// tokenize\n",
    "val tokenizer = new RegexTokenizer()\n",
    ".setInputCol(\"reviewText\")\n",
    ".setOutputCol(\"words\")\n",
    ".setPattern(split_pattern)\n",
    "\n",
    "// remove stopwords\n",
    "val stopWordsFile = path_to_stopwords\n",
    "val remover = new StopWordsRemover()\n",
    ".setInputCol(tokenizer.getOutputCol)\n",
    ".setOutputCol(\"filtered\")\n",
    ".setStopWords(stopwords)\n",
    "\n",
    "// turn words into numerical features\n",
    "val hashingTF = new HashingTF()\n",
    ".setInputCol(remover.getOutputCol)\n",
    ".setOutputCol(\"rawFeatures\")\n",
    "\n",
    "// scale feature\n",
    "val idf = new IDF()\n",
    ".setInputCol(hashingTF.getOutputCol)\n",
    ".setOutputCol(\"features\")\n",
    "\n",
    "// encode category to numerical label\n",
    "val indexer = new StringIndexer()\n",
    ".setInputCol(\"category\")\n",
    ".setOutputCol(\"label\")\n",
    "\n",
    "// ChiSqSelector\n",
    "val selector = new ChiSqSelector()\n",
    ".setNumTopFeatures(k)\n",
    ".setFeaturesCol(idf.getOutputCol)\n",
    ".setLabelCol(indexer.getOutputCol)\n",
    ".setOutputCol(\"selected_features\")\n",
    "\n",
    "val pipeline_feature_extraction = new Pipeline().setStages(Array(tokenizer, remover, hashingTF, idf, indexer, selector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8302918b-b049-46ab-a4af-b83a5dffe87e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.{LinearSVC, OneVsRest}\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
       "import org.apache.spark.sql.DataFrame\n",
       "train: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [category: string, reviewText: string]\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [category: string, reviewText: string]\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train, test) = reviewsDF\n",
    ".sample(withReplacement = false, fraction = 0.05, seed = 42)\n",
    ".randomSplit(Array(0.8,0.2), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "061fe731-14e9-4335-86ea-2044366ce4d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+\n",
      "|        category|          reviewText|\n",
      "+----------------+--------------------+\n",
      "|Apps_for_Android|6 inches on a rea...|\n",
      "|Apps_for_Android|A fun and very ad...|\n",
      "|Apps_for_Android|Amazing very addi...|\n",
      "|Apps_for_Android|An enjoyable puzz...|\n",
      "|Apps_for_Android|App has links to ...|\n",
      "+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "75f6ec56-ef5e-42a6-b35b-973063216649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalizer: org.apache.spark.ml.feature.Normalizer = Normalizer: uid=normalizer_021404c2b9e7, p=2.0\n",
       "svm: org.apache.spark.ml.classification.LinearSVC = linearsvc_592faa63a5e8\n",
       "ovr_svm: org.apache.spark.ml.classification.OneVsRest = oneVsRest_6d359e69b5de\n",
       "pipeline_train_model: org.apache.spark.ml.Pipeline = pipeline_4b73dc37023a\n"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val normalizer = new Normalizer()\n",
    "  .setInputCol(selector.getOutputCol)\n",
    "  .setOutputCol(\"normalized_features\")\n",
    "  .setP(2.0) // L2 normalization\n",
    "\n",
    "val svm = new LinearSVC()\n",
    ".setFeaturesCol(normalizer.getOutputCol)\n",
    ".setLabelCol(indexer.getOutputCol)\n",
    "\n",
    "val ovr_svm = new OneVsRest()\n",
    ".setClassifier(svm)\n",
    ".setFeaturesCol(normalizer.getOutputCol)\n",
    ".setLabelCol(indexer.getOutputCol)\n",
    "\n",
    "val pipeline_train_model = new Pipeline()\n",
    ".setStages(Array(pipeline_feature_extraction, normalizer, ovr_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d2c400a-4979-4452-afd0-dda9841dd207",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svm_model: org.apache.spark.ml.PipelineModel = pipeline_59b053669de1\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// train the model \n",
    "val svm_model = pipeline_train_model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ed4f702f-3b4b-4486-8642-17defe20562c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions: org.apache.spark.sql.DataFrame = [category: string, reviewText: string ... 9 more fields]\n"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// predict on test data\n",
    "val predictions = svm_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f7d8bbe-75d2-4e82-ab75-a10cdcdda00e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----------+\n",
      "|        category|label|prediction|\n",
      "+----------------+-----+----------+\n",
      "|Apps_for_Android|  8.0|       9.0|\n",
      "|Apps_for_Android|  8.0|       3.0|\n",
      "|Apps_for_Android|  8.0|       8.0|\n",
      "|Apps_for_Android|  8.0|       0.0|\n",
      "|Apps_for_Android|  8.0|      12.0|\n",
      "|Apps_for_Android|  8.0|       0.0|\n",
      "|Apps_for_Android|  8.0|       0.0|\n",
      "|Apps_for_Android|  8.0|       6.0|\n",
      "|Apps_for_Android|  8.0|       0.0|\n",
      "|Apps_for_Android|  8.0|       8.0|\n",
      "|Apps_for_Android|  8.0|       3.0|\n",
      "|Apps_for_Android|  8.0|       3.0|\n",
      "|Apps_for_Android|  8.0|       0.0|\n",
      "|Apps_for_Android|  8.0|       8.0|\n",
      "|Apps_for_Android|  8.0|      20.0|\n",
      "|Apps_for_Android|  8.0|       0.0|\n",
      "|Apps_for_Android|  8.0|      20.0|\n",
      "|Apps_for_Android|  8.0|       0.0|\n",
      "|Apps_for_Android|  8.0|       0.0|\n",
      "|Apps_for_Android|  8.0|       8.0|\n",
      "+----------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"category\",\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "151c6f21-fa19-481e-9c79-8742df2072fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = MulticlassClassificationEvaluator: uid=mcEval_8f4b42641310, metricName=f1, metricLabel=0.0, beta=1.0, eps=1.0E-15\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = new MulticlassClassificationEvaluator()\n",
    ".setMetricName(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5d459392-a963-4b25-8749-a00ccf6d4b63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score_default_model: Double = 0.35558985563198786\n"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val f1_score_default_model = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "da46e832-a270-42a7-a621-23f2146ad1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
       "evaluator_f1: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = MulticlassClassificationEvaluator: uid=mcEval_d93589f1d259, metricName=f1, metricLabel=0.0, beta=1.0, eps=1.0E-15\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\tlinearsvc_592faa63a5e8-maxIter: 8,\n",
       "\tchiSqSelector_e407ba37d885-numTopFeatures: 144,\n",
       "\tlinearsvc_592faa63a5e8-regParam: 0.05,\n",
       "\tlinearsvc_592faa63a5e8-standardization: false\n",
       "}, {\n",
       "\tlinearsvc_592faa63a5e8-maxIter: 8,\n",
       "\tchiSqSelector_e407ba37d885-numTopFeatures: 144,\n",
       "\tlinearsvc_592faa63a5e8-regParam: 0.13,\n",
       "\tlinearsvc_592faa63a5e8-standardization: false\n",
       "}, {\n",
       "\tlinearsvc_592faa63a5e8-maxIter: 8,\n",
       "\tchiSqSelector_e407ba37d885-numTopFeatures: 144,\n",
       "\tlinearsvc_592faa63a5e8-r...\n"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
    "\n",
    "val evaluator_f1 = new MulticlassClassificationEvaluator()\n",
    ".setMetricName(\"f1\")\n",
    "\n",
    "val paramGrid = new ParamGridBuilder()\n",
    ".addGrid(svm.maxIter, Array(8,34))\n",
    ".addGrid(svm.regParam, Array(0.05, 0.13, 0.55))\n",
    ".addGrid(selector.numTopFeatures, Array(144, 2000))\n",
    ".addGrid(svm.standardization, Array(false, true))\n",
    ".build()\n",
    "\n",
    "val trainValidationSplit = new TrainValidationSplit()\n",
    ".setEstimator(pipeline_train_model)\n",
    ".setEvaluator(evaluator_f1)\n",
    ".setEstimatorParamMaps(paramGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c2f207a7-6acf-4ee9-b21c-db7b5f5f3e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grid_search_model: org.apache.spark.ml.tuning.TrainValidationSplitModel = TrainValidationSplitModel: uid=tvs_0c02f78a59ee, bestModel=pipeline_4b73dc37023a, trainRatio=0.75\n"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "val grid_search_model = trainValidationSplit.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4ef8cc41-2dc3-4289-a537-e315442fdafc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "5: error: ';' expected but ',' found.",
     "output_type": "error",
     "traceback": [
      "<console>:5: error: ';' expected but ',' found.",
      "       f1_score_default_model, f1_score_grid_search_model",
      "                             ^",
      ""
     ]
    }
   ],
   "source": [
    "val grid_search_predicton = grid_search_model.transform(test)\n",
    "val f1_score_grid_search_model = evaluator.evaluate(grid_search_predicton)\n",
    "\n",
    "f1_score_default_model, f1_score_grid_search_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
